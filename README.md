# Attention-is-all-you-need复现
项目复现了attention is all you need论文中transformer结构，并进行了训练，在1080Ti上训练四天左右，loss下降到0-1之间，还没有测试准确率
